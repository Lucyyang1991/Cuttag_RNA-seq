# 服务器使用说明

## 1. 服务器基本信息

### 1.1 服务器架构
- **登录节点**：mgt (32核心，62.2GB内存)
- **计算节点1**：node01 (80核心，376.2GB内存)
- **计算节点2**：node02 (80核心，376.2GB内存)

### 1.2 注意事项
- 所有计算密集型任务**必须**通过SGE系统提交到计算节点运行
- **禁止**在登录节点(mgt)上直接运行大型计算任务
- 合理申请计算资源，避免资源浪费

## 2. 任务提交指南

### 2.1 基本任务提交
```bash
# 提交任务的基本命令
qsub your_script.sh          # 默认提交到all.q队列，由SGE自动选择节点
qsub -q all.q your_script.sh # 与上面命令效果相同

# 指定节点提交任务
qsub -q all.q@node01 your_script.sh  # 指定在node01上运行
qsub -q all.q@node02 your_script.sh  # 指定在node02上运行

# 查看任务状态
qstat

# 删除任务
qdel job_id
```

### 2.2 节点选择说明
1. **默认提交行为**：
   - 不带任何队列参数时（`qsub your_script.sh`），任务会自动提交到`all.q`队列
   - `all.q`队列包含所有计算节点（node01和node02）
   - SGE会根据当前负载情况自动选择合适的节点运行任务

2. **自动分配**（推荐）：
   - 显式指定队列但不指定节点：`qsub -q all.q your_script.sh`
   - SGE会自动根据负载情况选择合适的节点
   - 这种方式与默认提交行为相同，但写法更明确

3. **指定节点**：
   - 语法：`-q all.q@节点名`
   - 可选节点：node01, node02
   - 示例：`-q all.q@node01`
   - 注意：除非特殊需求，不建议指定节点，以免造成节点负载不均衡

4. **节点选择建议**：
   - 普通任务：使用自动分配
   - 特殊任务（如需要特定节点资源）：指定节点
   - 大型任务：观察节点负载后选择负载较低的节点

### 2.3 任务脚本模板
根据任务规模选择合适的资源配置：

1. **小型任务**（如FastQC、文件处理等）：
```bash
#!/bin/bash
#$ -S /bin/bash
#$ -N job_name          # 作业名称
#$ -cwd                 # 使用当前目录
#$ -j y                 # 合并标准输出和错误输出
#$ -o logs/$JOB_NAME.log  # 日志输出路径
#$ -q all.q             # 队列指定（自动分配节点）
#$ -l h_vmem=4G        # 申请4GB内存
#$ -pe smp 2           # 申请2个CPU线程

# 加载环境（如果需要）
source activate your_env

# 运行命令
your_commands_here
```

2. **中型任务**（如比对、峰值检测等）：
```bash
#!/bin/bash
#$ -S /bin/bash
#$ -N job_name
#$ -cwd
#$ -j y
#$ -o logs/$JOB_NAME.log
#$ -q all.q@node01      # 指定在node01上运行
#$ -l h_vmem=16G       # 申请16GB内存
#$ -pe smp 8           # 申请8个CPU线程

source activate your_env
your_commands_here
```

3. **大型任务**（如大规模数据处理）：
```bash
#!/bin/bash
#$ -S /bin/bash
#$ -N job_name
#$ -cwd
#$ -j y
#$ -o logs/$JOB_NAME.log
#$ -q all.q@node02      # 指定在node02上运行
#$ -l h_vmem=32G       # 申请32GB内存
#$ -pe smp 16          # 申请16个CPU线程

source activate your_env
your_commands_here
```

### 2.4 批量任务处理
对于需要处理多个样本的情况，推荐使用以下方式：

1. **任务数组方式**（适合处理多个相似任务）：
   - 优点：脚本简洁，易于管理
   - 适用场景：所有样本的处理逻辑相同
   - 示例：对多个FASTQ文件进行质控分析

```bash
#!/bin/bash
#$ -S /bin/bash
#$ -N fastqc_array
#$ -cwd
#$ -j y
#$ -o logs/fastqc_$TASK_ID.log
#$ -q all.q
#$ -t 1-24            # 设置任务数量
#$ -l h_vmem=4G
#$ -pe smp 2

# 创建输出目录
mkdir -p fastqc_results logs

# 定义样本数组（实际使用时替换为您的样本名）
samples=(
    "sample1_R1"
    "sample1_R2"
    "sample2_R1"
    "sample2_R2"
    # ... 更多样本
)

# 获取当前任务对应的样本
current_sample=${samples[$SGE_TASK_ID-1]}

# 激活环境
source activate cuttag

# 运行FastQC
echo "处理样本: ${current_sample}"
fastqc \
    ./raw_data/${current_sample}.fastq.gz \
    -o ./fastqc_results \
    -t 2

echo "完成样本: ${current_sample}"
```

2. **任务生成器方式**（适合复杂的样本处理流程）：
   - 优点：更灵活，可以为每个样本设置不同参数
   - 适用场景：样本间处理逻辑有差异
   - 示例：不同样本使用不同参数进行质控

```bash
#!/bin/bash
# 任务生成和提交脚本

# 创建必要的目录
mkdir -p logs job_scripts fastqc_results

# 样本参数配置（实际使用时根据需要修改）
declare -A sample_params=(
    ["sample1"]="--nogroup --noextract"
    ["sample2"]="--nogroup --extract"
    ["sample3"]="--adapters ~/adapters.txt"
)

# 为每个样本生成任务脚本
for sample in "${!sample_params[@]}"; do
    params=${sample_params[$sample]}
    
    # 创建该样本的作业脚本
    cat > job_scripts/fastqc_${sample}.sh << EOF
#!/bin/bash
#$ -S /bin/bash
#$ -N fastqc_${sample}
#$ -cwd
#$ -j y
#$ -o logs/${sample}_fastqc.log
#$ -q all.q
#$ -l h_vmem=4G
#$ -pe smp 2

# 激活环境
source activate cuttag

echo "开始处理样本: ${sample}"

# 运行FastQC，使用样本特定参数
fastqc \\
    ./raw_data/${sample}_R1.fastq.gz \\
    ./raw_data/${sample}_R2.fastq.gz \\
    -o ./fastqc_results \\
    -t 2 \\
    ${params}

echo "完成样本: ${sample}"
EOF

    # 提交作业
    echo "提交样本 ${sample} 的FastQC分析任务..."
    qsub job_scripts/fastqc_${sample}.sh
done

echo "所有FastQC分析任务已提交"
```

3. **任务依赖示例**（当任务间存在依赖关系）：
```bash
#!/bin/bash
# 示例：FastQC完成后运行MultiQC汇总报告

# 首先提交FastQC任务
fastqc_job=$(qsub fastqc_array.sh)
fastqc_job_id=$(echo $fastqc_job | cut -d' ' -f3)

# 创建MultiQC任务脚本
cat > multiqc_job.sh << EOF
#!/bin/bash
#$ -S /bin/bash
#$ -N multiqc
#$ -cwd
#$ -j y
#$ -o logs/multiqc.log
#$ -q all.q
#$ -l h_vmem=4G
#$ -pe smp 1

source activate cuttag

# 运行MultiQC
multiqc ./fastqc_results -o ./multiqc_results
EOF

# 提交MultiQC任务，等待FastQC任务完成后运行
qsub -hold_jid $fastqc_job_id multiqc_job.sh
```

4. **批量任务管理技巧**：
   - 使用有意义的作业名便于管理：
     ```bash
     #$ -N sample1_fastqc    # 而不是简单的 job1
     ```
   - 使用结构化的日志目录：
     ```bash
     mkdir -p logs/{fastqc,alignment,peaks}
     ```
   - 添加错误检查和报告：
     ```bash
     # 检查任务完成状态
     if [ $? -eq 0 ]; then
         echo "任务成功完成"
     else
         echo "任务失败，错误码: $?"
         exit 1
     fi
     ```
   - 使用配置文件管理参数：
     ```bash
     # config.sh
     FASTQ_DIR="./raw_data"
     RESULT_DIR="./results"
     THREADS=2
     MEM="4G"
     ```

## 3. 常用命令说明

### 3.1 任务管理命令
```bash
qstat           # 查看所有任务状态
qstat -j JobID  # 查看特定任务详细信息
qdel JobID      # 删除特定任务
qdel -u 用户名   # 删除该用户的所有任务
```

### 3.2 任务状态说明
1. **任务状态类型**：
   - `qw`（queuing/waiting）：等待状态，任务在排队等待资源
   - `r`（running）：运行状态，任务正在执行
   - `Eqw`（error）：错误状态，提交参数有误或其他错误
   - `t`（transferring）：传输状态，任务正在传输到执行节点
   - `dr`（deleted）：删除状态，任务正在被删除

2. **资源不足时的处理**：
   - 任务会自动进入等待队列（qw状态）
   - 当资源满足要求时，任务会自动开始运行
   - 无需手动重新提交任务
   - 等待队列采用先进先出（FIFO）原则

3. **查看任务详细信息**：
```bash
# 查看任务详细信息，包括等待原因
qstat -j JobID

# 查看所有任务的资源需求
qstat -f

# 查看队列负载情况
qstat -g c

# 查看节点资源使用情况
qhost -F
```

4. **任务优先级说明**：
   - 默认按提交时间排序（先提交先执行）
   - 任务开始执行前可以删除（`qdel JobID`）
   - 长时间等待的任务不会自动取消

5. **任务等待时间评估**：
   - 使用`qstat -g c`查看队列整体负载
   - 使用`qhost`查看各节点资源使用情况
   - 评估等待时间，合理安排任务提交

6. **任务状态示例解析**：
```bash
$ qstat
job-ID  prior  name     user     state  submit/start at      queue         slots ja-task-ID
----------------------------------------------------------------------------------
  12345  0.50   fastqc   user1    qw    02/20/2024 10:30    all.q            2
  12346  0.50   bowtie2  user1    r     02/20/2024 10:31    all.q@node01     8
  12347  0.50   macs2    user2    Eqw   02/20/2024 10:32    all.q            4
  12348  0.50   seacr    user1    t     02/20/2024 10:33    all.q@node02     4
```
状态说明：
- 任务12345：等待资源中（qw）
- 任务12346：正在node01上运行（r）
- 任务12347：提交出错（Eqw）
- 任务12348：正在传输到node02（t）

7. **等待时间估算方法**：
```bash
# 步骤1：查看当前队列负载
$ qstat -g c
CLUSTER QUEUE   CQLOAD   USED    RES  AVAIL  TOTAL aoACDS  cdsuE  
--------------------------------------------------------------------------------
all.q           1.00     120      0     40    160      0      0 

# 步骤2：查看节点详细资源
$ qhost -F
node01     160    120      40     45.97   376.2G   300.5G
node02     160    120      40     59.36   376.2G   280.8G
```
等待时间评估方法：
- 检查已用资源（USED）和可用资源（AVAIL）
- 观察节点负载（CQLOAD）：接近1表示队列较忙
- 评估内存使用情况：已用内存/总内存
- 粗略估算：
  * 轻负载（CQLOAD < 0.5）：通常无需等待
  * 中负载（0.5-0.8）：可能需要等待5-15分钟
  * 重负载（>0.8）：可能需要等待15-30分钟以上

8. **常见等待原因和解决方案**：

| 等待原因 | 现象 | 解决方案 |
|---------|------|---------|
| 资源不足 | qw状态，qstat -j显示"waiting for resources" | - 减少资源申请（降低h_vmem或smp）<br>- 选择负载较低的节点<br>- 错峰提交（非高峰时段） |
| 内存超限 | Eqw状态，日志显示"memory limit exceeded" | - 增加h_vmem值<br>- 减少并行数（降低smp）<br>- 优化程序减少内存使用 |
| 队列已满 | qw状态，显示"queue full" | - 等待其他任务完成<br>- 联系管理员增加队列容量 |
| 节点故障 | Eqw状态，无法连接节点 | - 使用qalter更改节点<br>- 重新提交到其他节点 |

9. **任务优化建议**：
- **高峰期策略**：
  * 将大型任务拆分为多个小任务
  * 使用任务数组代替单个大任务
  * 选择资源较空闲的节点

- **低峰期策略**：
  * 合并小任务减少调度开销
  * 可以申请较多资源
  * 适合运行大型分析任务

- **资源平衡**：
  * 内存密集型任务：增加h_vmem，减少smp
  * 计算密集型任务：减少h_vmem，增加smp
  * 综合考虑任务特性和当前集群负载

10. **常用排查命令**：
```bash
# 查看任务详细信息和等待原因
qstat -j JobID | grep -E 'usage|error|waiting'

# 查看节点负载历史
qhost -F -j

# 检查任务日志文件
tail -f logs/JobName.oJobID

# 修改正在等待的任务参数
qalter -l h_vmem=8G JobID  # 修改内存限制
qalter -pe smp 4 JobID     # 修改CPU核心数
```

### 3.3 资源查看命令
```bash
qhost          # 查看节点状态
qhost -q       # 查看节点和队列详细信息
qstat -g c     # 查看队列状态
```

## 4. 资源使用建议

### 4.1 资源申请原则
- 根据任务实际需求申请资源，避免过度申请
- 对于未知资源需求的任务，建议先小规模测试
- 注意监控任务运行状态，及时处理异常情况

### 4.2 内存申请说明
1. **内存参数说明**：
   - `h_vmem`：指定每个核心（slot）的内存限制
   - 实际总内存 = `h_vmem` × 申请的核心数（`-pe smp`指定的值）
   - 示例：如果设置 `#$ -l h_vmem=4G -pe smp 4`，则总内存限制为 16GB

2. **内存超限处理**：
   - 如果任务实际使用内存超过限制，SGE会自动终止任务
   - 任务日志中会显示"Killed"或内存相关的错误信息
   - 建议预留20-30%的内存余量，避免任务被终止

3. **内存申请建议**：
   - 首次运行时可以通过小数据测试评估内存需求
   - 可以使用`qstat -j job_id`查看任务的内存使用情况
   - 如果不确定内存需求，建议：
     ```bash
     # 保守方式：每核心申请较大内存
     #$ -l h_vmem=8G
     #$ -pe smp 4
     
     # 激进方式：多申请核心，每核心较少内存
     #$ -l h_vmem=2G
     #$ -pe smp 16
     ```

4. **常见错误处理**：
   - 内存不足报错：增加`h_vmem`值或减少并行核心数
   - 任务被终止：检查内存使用峰值，适当增加限制
   - 节点资源不足：调整`h_vmem`和`smp`的配比

### 4.3 推荐配置
1. 文件处理类任务：2-4核，4-8G内存
2. 数据分析类任务：8-16核，16-32G内存
3. 大规模计算任务：16-32核，32-64G内存

### 4.4 注意事项
- 脚本文件不需要设置可执行权限，直接使用`qsub script.sh`提交即可
- 确保输出目录存在
- 使用有意义的作业名，便于管理
- 及时清理不需要的任务和输出文件

## 5. 常见问题解决

### 5.1 任务未启动
- 检查脚本权限
- 检查资源申请是否合理
- 查看详细错误信息：`qstat -j JobID`

### 5.2 任务异常退出
- 检查错误日志
- 确认环境变量是否正确
- 验证输入文件是否存在

### 5.3 资源使用过高
- 调整资源申请参数
- 优化处理流程
- 考虑拆分大型任务

## 6. 联系方式
如遇到问题，请联系：
- 系统管理员：杨璐
- 联系电话：13810247699

## 7. 更新记录
